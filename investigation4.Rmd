---
title: "investigation4"
author: "Emily"
date: "6/30/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
{
  c("alphahull",     # To calculate the convex hull
    "ca",            # Correspondence analysis
    "conflicted",    # To deal with conflicting function names
    # I've had some strangeness with this
    #  script. I suspect package:conflicted,
    #  but I don't yet know for sure.
    "data.table",    # Fast data input/output
    "dplyr",         # This is all of tidyverse that gets used here
    "dtplyr",        # dplyr syntax with a data.table backend
    "here",          # To find/store files w/o setwd() and getwd()
    "igraph",        # Basic network tools; we'll use statnet mostly
    "igraphdata",    # Some useful datasets
    "intergraph",    # Translate between igraph and statnet formats
    "lmPerm",        # To do permutation tests
    "statnet",      # A suite of network tools, including ERGM and more
    "xlsx"
  ) -> package_names
  
  for (package_name in package_names) {
    if (!is.element(package_name, installed.packages()[, 1])) {
      install.packages(package_name,
                       repos = "http://cran.mtu.edu/")
      # An alternate, just in case.
      #                      repos="http://lib.stat.cmu.edu/R/CRAN")
    }
    library(
      package_name,
      character.only = TRUE,
      quietly = TRUE,
      verbose = FALSE
    )
  }
  rm(list = c("package_name", "package_names"))
}

set_here()

# Because I like these options:
options(show.signif.stars = FALSE)
options(digits = 4)

install.packages("Rtools")

```

##the prompt
In this investigation, you'll work with a large-ish data set taken from Trampe, Quoidbach, & Taquet's (2015) Emotions in Everyday Life. (It's available at PLoS ONE 10(12): e0145450, if you want to read it.)

You'll first create a co-occurrence network. (That is, one emotion links to another if it occurs at the same time and day as what other emotion. This will be a weighted network, with the weight equal to the number of times there is a co-occurrence.) Then you will explore the centrality for the emotions that appear from those networks. Note first that the dataset consists of an ID, a day and time for the emotion, and then whether each of the 18 emotions is present (1) or absent (0).

For this network, construct a weighted network of emotions that are linked if the two emotions occur at the same day and same time. (This is gonna require some data wrangling!) Then, find which emotion is the most central: Pick an appropriate centrality measure, defend your choice, and then determine the emotions' centrality. Which is most central? Which is least?

Once you have a central emotion, then do something else with the data set. You might want to look at which links are more or less frequent than expected (see last week), or do an ERGM, or maybe do something with comparing centralities, or whatever.
```{r the data}
#Im not really sure how to go about all of the points abve, and thinking about it makes me overwhelemed... so Im going to just start doing things... 


load("C:/Users/Emily_Ferry/Desktop/SJFC/Borgatti-master/investData/Emotions.RData")
emotion_raw

#edges 
install.packages("tidyverse")
library(tidyverse)
library(tidyr)
install.packages("dpylr")
library(dplyr)



emotion_l <- emotion_raw %>%
  gather(emotion_type, value, Pride:Anger) %>%
  arrange(id, Day) %>%
  dplyr::filter(value == 1) %>%
  select(-value)

emotion_l
#need to link to make the edges, need to link one emotion to the next

emotion_edges <- emotion_l %>%
  mutate(second_emotion = lead(emotion_type)) %>%
  rename(first_emotion = emotion_type) %>%
  select(id, Day, Hours, first_emotion, second_emotion) %>%
  group_by(id) %>%
  slice(-length(id))

emotion_edges
#connected the emotions in a chain like sense, offense to sadness, sadness to disgust. This does sort of ignore people having multiple emotions at once, but thats sort of the drawback I am not really sure how to do this / ensure that two emotions ocurre on the same day? 


#need the nodes, emotions 
emotion_nodes <- emotion_l %>%
  count(emotion_type) %>%
  rowid_to_column("id") %>%
  rename(label = emotion_type) %>%
  mutate(valence = ifelse(label %in% c("Awe", "Amusement", "Joy", "Alertness", "Hope","Love","Gratitude","Pride","Satisfaction"), "positive", "negative"))

emotion_nodes


```
We have peices of the network, edges and nodes, now I need to weight the data 


```{r the newtork}

emotion_network <- emotion_edges %>%
  group_by(first_emotion, second_emotion) %>%
  summarize(weight = n()) %>%
  ungroup() %>%
  select(first_emotion, second_emotion, weight)

emotion_network



network(emotion_network,directed=FALSE)->emo_net
#(sna:degree(emo_net))/2->degs wanted to make sure double counting doesnt occure I think, but I cant get CRAN and I cant find it on like github to find 
set.seed(42)
plot(emo_net)
#plot.network(emotion_network,attrname= emotion_edges,label = network.vertex.names(emotion_nodes))



```
I am stuck so I googled and Im going to follow some things 

```{r resorting to doing something here}


edges <- emotion_network %>%
  left_join(emotion_nodes, by = c("first_emotion" = "label")) %>%
  rename(from = id)

edges <- edges %>%
  left_join(emotion_nodes, by = c("second_emotion" = "label")) %>%
  rename(to = id) %>%
  select(from, to, weight) %>%
  mutate(weight = ifelse(weight > 4500, 4500, weight)) #trimmed high values out for better graphing 

install.packages("tidygraph")
library(tidygraph)
library(ggraph)

network <- tbl_graph(emotion_nodes, edges, directed = TRUE)


```

